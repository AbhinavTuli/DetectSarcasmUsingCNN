{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLHc0FpRqzbq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from collections import defaultdict\n",
    "from torchtext import data\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from torchtext import data,vocab\n",
    "from tqdm.notebook import tqdm, tqdm_notebook,tnrange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "vWUyZxt2r7-y",
    "outputId": "6b6d3e34-ff7a-4c4f-f47d-5341345107ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sanchit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89oGX-ZEqzdW"
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return re.findall(r\"[\\w']+|[.,!?;]\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NHONJFblP32"
   },
   "outputs": [],
   "source": [
    "featstrain = {}\n",
    "featstest = {}\n",
    "import csv\n",
    "with open ('trainOPN.csv',newline = '') as file:\n",
    "  read = csv.reader(file,delimiter = ',') \n",
    "  for line in read:\n",
    "    # print(line)\n",
    "    temp = line[2].split(' ')\n",
    "    temp = [float(f) for f in temp]\n",
    "    featstrain[int(line[3])] = temp\n",
    "\n",
    "with open ('testOPN.csv',newline = '') as file:\n",
    "  read = csv.reader(file,delimiter = ',')\n",
    "  for line in read:\n",
    "    temp = line[2].split(' ')\n",
    "    temp = [float(f) for f in temp]\n",
    "    featstest[int(line[3])] = temp\n",
    "# print((featstest[322]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "308w9SoSqzdb"
   },
   "outputs": [],
   "source": [
    "txt_field = data.Field(sequential = True,tokenize = tokenize,include_lengths = False, use_vocab = True)\n",
    "label_field = data.Field(sequential = False,use_vocab=False,pad_token=None,unk_token=None)\n",
    "vec_field = data.Field(sequential = False,use_vocab =False , pad_token= None, unk_token = None)\n",
    "train_val_fields = [('EssayText',txt_field),('Personality',label_field),('Mariesse',None),('idx',vec_field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = vocab.Vectors('glove.6B.300d.txt','./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Bz3ePcAqzdg"
   },
   "outputs": [],
   "source": [
    "train,val = data.TabularDataset.splits(path = './',format = 'csv',train='trainOPN.csv',validation = 'testOPN.csv',fields = train_val_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y73E-mRYqzdq"
   },
   "outputs": [],
   "source": [
    "txt_field.build_vocab(train,val,vectors = vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "TaU7Upq0qzdu",
    "outputId": "9fa10952-261c-42d2-d19b-d32ee593c4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "label_field.build_vocab(train)\n",
    "# vec_field.build_vocab(train)\n",
    "# print(txt_field.vocab.vectors.shape)\n",
    "print((txt_field).vocab['!'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgHmb39yqzdz"
   },
   "outputs": [],
   "source": [
    "traindl,valdl = data.BucketIterator.splits(datasets=(train,val),batch_size = 16,device = device,sort_key = lambda x : len(x.EssayText),sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "I6t12oD70Q3P",
    "outputId": "d0752cae-f284-48fd-9d13-835f33a167c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 342, 1191,    3,  ...,    1,    1,    1], device='cuda:0')\n",
      "1388\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(traindl))\n",
    "# print(dir(batch))\n",
    "print((batch.EssayText[:,0]))\n",
    "test_list=(batch.EssayText[:,0]).tolist()\n",
    "print(len(test_list))\n",
    "def text_to_sent(test_list):\n",
    "    size = len(test_list) \n",
    "    idx_list = [idx + 1 for idx, val in\n",
    "            enumerate(test_list) if val == 2 or val == 55 or val == 64 ]\n",
    "\n",
    "    temp_li_final = [test_list[i: j] for i, j in\n",
    "        zip([0] + idx_list, idx_list + \n",
    "        ([size] if idx_list[-1] != size else []))] \n",
    "    return temp_li_final\n",
    "temp_li_final = text_to_sent(test_list)\n",
    "    \n",
    "# temp_sent2 = []\n",
    "# for i in temp_li_final:\n",
    "#     temp_sent = ''\n",
    "#     for x in (i):\n",
    "#         word = txt_field.vocab.itos[x]\n",
    "#         temp_sent += word + ' '\n",
    "#     temp_sent2.append(temp_sent)\n",
    "\n",
    "# print((temp_sent2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1Kob0upqzeF"
   },
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx = pad_idx)\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim,out_channels = 50,kernel_size = fs) for fs in (1,2,3)])\n",
    "        self.conv2 = nn.Conv1d(in_channels = 50,out_channels = 100,kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(224884,50) #Change this \n",
    "        self.fc2 = nn.Linear(50,1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self,text,len_sentences):\n",
    "        print(\"text\",text.size())\n",
    "        embedded = self.embedding(text.T)\n",
    "        embedded = embedded.permute(0,2,1)\n",
    "        print(embedded.size(),\"embedded\")\n",
    "        # mariesse = [float(f) for f in mariesse]\n",
    "#         mariesse = torch.from_numpy(mariesse).float()\n",
    "#         mariesse = torch.tensor(mariesse,device = device,dtype = embedded.dtype)\n",
    "        # print(mariesse.size(),\"mariesse\")\n",
    "        # mariesse = torch.FloatTensor(mariesse,dtype = embedded,device = embedded.device)\n",
    "        x=embedded.size(2)\n",
    "        y=3000-x\n",
    "        # print(y,\"hello\")\n",
    "        batch_size=embedded.size(0)\n",
    "        # z=np.zeros((batch_size,100,y,dtype = embedded.dtype,device = embedded.device))\n",
    "        z = torch.zeros(batch_size,300,y,dtype = embedded.dtype,device = embedded.device)\n",
    "        # z1=torch.from_numpy(z).float()\n",
    "        lz=[embedded,z]\n",
    "        # print(type(embedded))\n",
    "        zcat = torch.cat(lz, dim = 2,)\n",
    "        print(\"zcat\",zcat.size())\n",
    "        conved = [F.relu(conv(zcat)) for conv in self.convs]\n",
    "        print(\"Conved sizes below\")\n",
    "        for c in conved:\n",
    "          print(c.size())\n",
    "        pooled = [F.max_pool1d(conv,(2)) for conv in conved]\n",
    "        print(\"Pool Sizes below\")\n",
    "        for pl in pooled:\n",
    "            print(pl.size())\n",
    "        cat = torch.cat(pooled,dim = 2)\n",
    "        print(\"cat after layer 1\",cat.size())\n",
    "        conved2 = F.relu(self.conv2(cat))\n",
    "        print(\"conved2\",conved2.size())\n",
    "        pooled2 = F.max_pool1d(conved2,2)\n",
    "        print(pooled2.size(),\"pooled after layer 1\")\n",
    "        pooled2 = pooled2.reshape(batch_size,224800)\n",
    "        # print(pooled2.size(),\"size2\")\n",
    "        # mairesse_layer = torch.from_numpy(matrix_mair).float()\n",
    "        # mairesse_layer.device = pooled2.device\n",
    "#         concat_mairesse = torch.cat([pooled2,mariesse],dim = 1)\n",
    "        # print(concat_mairesse.size(),\"concat\")\n",
    "        # print(pooled2.size(),\"pooled2\")\n",
    "        full1 = self.fc1(pooled2)\n",
    "        final1 = self.dropout(full1)\n",
    "        full2 = self.fc2(final1)\n",
    "        # final = self.dropout(full2)\n",
    "        return full2\n",
    "#         return pooled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "BClD8n1uqzeJ",
    "outputId": "6c1697b9-77a2-45ef-9ba0-b28e1c333a94"
   },
   "outputs": [],
   "source": [
    "input_dim = len(txt_field.vocab)\n",
    "embedding_dim = 300\n",
    "pad_idx = txt_field.vocab.stoi[txt_field.pad_token]\n",
    "model = CNN1d(input_dim,embedding_dim,pad_idx)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "WUWwjXnqqzeN",
    "outputId": "2d2ca07b-d2a4-48d6-d8d4-4755c5ca53f9"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "ex = next(iter(traindl))\n",
    "print(ex.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "qsvutZ9nqzeQ",
    "outputId": "d1cbbd1d-39e5-46af-d02f-d228cc423cbc"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = txt_field.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xmdaRkgqzeU"
   },
   "outputs": [],
   "source": [
    "unk_idx = txt_field.vocab.stoi[txt_field.unk_token]\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(300)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OplDEktqzeY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opMkLyCCqzeb"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0T-UGcJIqzeh"
   },
   "outputs": [],
   "source": [
    "def train(model,iterator,optimizer,criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        mariesse_vecs = np.zeros((batch.batch_size,84))\n",
    "#         j = 0\n",
    "#         temp_idx = batch.idx.tolist()\n",
    "#         temp_idx = [int(i) for i in temp_idx]\n",
    "#         for i in temp_idx:\n",
    "#           mariesse_vecs[j] = featstrain[i]\n",
    "#           j += 1\n",
    "        for idx in range(len(batch.batch_size)):\n",
    "            test_list=(batch.EssayText[:,idx]).tolist()\n",
    "            temp_li_final = text_to_sent(test_list)\n",
    "            preds = []\n",
    "            for sent in temp_li_final:\n",
    "                predictions = model(sent).squeeze(1)\n",
    "                preds.append(predictions)\n",
    "            preds\n",
    "            \n",
    "        batch.Personality = batch.Personality.type_as(predictions)\n",
    "        loss = criterion(predictions,batch.Personality)\n",
    "        acc = binary_accuracy(predictions,batch.Personality)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTpDv4jAqzek"
   },
   "outputs": [],
   "source": [
    "def evaluate(model,iterator,criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            mariesse_vecs = np.zeros((batch.batch_size,84))\n",
    "            j = 0\n",
    "            temp_idx = batch.idx.tolist()\n",
    "            temp_idx = [int(i) for i in temp_idx]\n",
    "            for i in temp_idx:\n",
    "              mariesse_vecs[j] = featstest[i]\n",
    "              j += 1 \n",
    "            predictions = model(batch.EssayText,mariesse_vecs).squeeze(1)\n",
    "            batch.Personality = batch.Personality.type_as(predictions)\n",
    "            loss = criterion(predictions,batch.Personality)\n",
    "            acc = binary_accuracy(predictions,batch.Personality)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poS2AXWzqzen"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o4YRqEMkqzes",
    "outputId": "4e62ecdf-d238-47da-8144-19ed04ec3280"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, traindl, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valdl, criterion)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8WByfmgR7i5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list)\n",
    "plt.plot(valid_loss_list)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','test'],loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQf7fEUuTB-R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
